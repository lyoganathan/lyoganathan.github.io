# obtain p-value:
2*pt(tval,df=24968,lower.tail = FALSE)
# DV Continous, IV Continous
numCalls = dt[, list(NumCalls=length(WordCount)), by = (Date=as.Date(ClientCaptureDate))]
View(numCalls)
plot(numCalls)
model1 = lm(NumCalls ~ Date, data = numCalls)
summary(model1)
ggplot(data = numCalls, aes(x=Date,y=NumCalls)) + geom_point() + geom_smooth(method="lm", se=FALSE)
ggplot(data = numCalls, aes(x=Date,y=NumCalls)) + geom_point() + geom_smooth(method="lm", formula=y~poly(x,3),se=FALSE)
ggplot(data = numCalls, aes(x=Date,y=NumCalls)) + geom_point() + geom_smooth(method="lm", formula=y~cos(x),se=FALSE)
ggplot(data = numCalls, aes(x=Date,y=NumCalls)) + geom_point() + geom_smooth(method="lm", formula=y~sin(x),se=FALSE)
ggplot(data = numCalls, aes(x=Date,y=NumCalls)) + geom_point() + geom_smooth(method="lm", formula=y~poly(x,3),se=FALSE)
ggplot(data=test_df,aes(x=UDF_text_07,y=WordCount,fill=UDF_text_07)) + geom_point()
ggplot(data=test_df,aes(x=UDF_text_07,y=WordCount,fill=UDF_text_07)) + geom_violin() + geom_point()
ggplot(data=test_df,aes(x=UDF_text_07,y=WordCount,fill=UDF_text_07)) + geom_violin() + geom_point()
ggplot(data=test_df,aes(x=UDF_text_07,y=WordCount,fill=UDF_text_07)) + geom_point()
ggplot(data=test_df,aes(x=UDF_text_07,y=WordCount,fill=UDF_text_07)) +geom_violin() + geom_point()
model2 = lm(WordCount ~ UDF_text_07, data = test_df)
summary(model2)
# Look at length and mean
test_df[, list(AvgWordCount=mean(WordCount),NumCalls=length(WordCount)), by = UDF_text_07]
plot.default(x=test_df$UDF_text_07, y=test_df$WordCount,xaxt='n')
axis(1, at=1:2, labels=seq(0,1,1))
lines(test_df$UDF_text_07, predict(model2),col='blue')
# Take only Sales and Retention word counts:
test_df = dt[dt$UDF_text_07 == c('Sales','Retention'), c("UDF_text_07","WordCount")]
#test_df = test_df[sample(.N,5000)]
# Have to remove unused factor level
test_df$UDF_text_07 = factor(test_df$UDF_text_07)
# Look at length and mean
test_df[, list(AvgWordCount=mean(WordCount),NumCalls=length(WordCount)), by = UDF_text_07]
# Difference between means:
diff(by(test_df$WordCount, test_df$UDF_text_07, mean))
d[,list(length(CONVERSION), sum(CONVERSION)),by=IS_TEST]
#
prop.test(x=c(1915,541),n=c(73721,18386))
mtrx = cbind(CONVERSIONS=c(1915,541), GROUP=c(73721,18386))
fisher.test(x=mtrx)
#
prop.test(x=c(1915,541),n=c(73721,18386))
model4 <- lm(CONVERSION ~ IS_TEST, data = d)
summary(model4)
ggplot(d, aes(x = IS_TEST, y = CONVERSION)) + geom_point() + geom_smooth(method='lm') #+ geom_jitter(width = 0.2, height = 0.1)
ggplot(d, aes(x = IS_TEST, y = CONVERSION)) + geom_point() + geom_smooth(method='lm') + geom_jitter(width = 0.2, height = 0.1)
fisher.test(x=mtrx)
summary(model4)
summary(model3)
# Calculate t-value manually:
# t = (x1-x2) / (sd1/sqrt(n1) + sd2/sqrt(n2))
x1 = mean(test_df$WordCount[test_df$UDF_text_07 == 'Sales'])
x2 = mean(test_df$WordCount[test_df$UDF_text_07 == 'Retention'])
n1 = length(test_df$WordCount[test_df$UDF_text_07 == 'Sales'])
n2 = length(test_df$WordCount[test_df$UDF_text_07 == 'Retention'])
var1 = var(test_df$WordCount[test_df$UDF_text_07 == 'Sales'])
var2 = var(test_df$WordCount[test_df$UDF_text_07 == 'Retention'])
tval = (x2-x1) / sqrt(var1/n1 + var2/n2)
# plot t-value on null distribution:
plot(x=seq(-3,3,0.1), y= dt(seq(-3,3,0.1),df=3860.9),type='l')
abline(v=tval, col = "blue", lwd = 2)
# Dr. Kristen Gorman
library(palmerpenguins)
penguins.head(5)
penguins
ggplot(penguins, aes(x=body_mass_g, fill=species)) + geom_density(alpha=0.8)
library(ggplot2)
ggplot(penguins, aes(x=body_mass_g, fill=species)) + geom_density(alpha=0.8)
#position='identity' makes sure its not stacked
ggplot(d, aes(x=WordCount, fill=UDF_text_07, color=UDF_text_07)) + geom_histogram(alpha=0.4, position='identity')
#position='identity' makes sure its not stacked
ggplot(penguins, aes(x=body_mass_g, fill=species, color=species)) + geom_histogram(alpha=0.4, position='identity')
penguins
#position='identity' makes sure its not stacked
ggplot(penguins, aes(x=flipper_length_mm, fill=species, color=species)) + geom_histogram(alpha=0.4, position='identity')
#position='identity' makes sure its not stacked
ggplot(penguins, aes(x=bill_length_mm, fill=species, color=species)) + geom_histogram(alpha=0.4, position='identity')
ggplot(penguins, aes(x=bill_length, fill=species)) + geom_density(alpha=0.8)
ggplot(penguins, aes(x=bill_length_mm, fill=species)) + geom_density(alpha=0.8)
ggplot(penguins, aes(x=body_mass_g, fill=species)) + geom_density(alpha=0.8)
#position='identity' makes sure its not stacked
ggplot(penguins, aes(x=body_mass_g, fill=species, color=species)) + geom_histogram(alpha=0.4, position='identity')
head(penguins,5)
library(palmerpenguins)
library(ggplot2)
head(penguins,5)
ggplot(penguins, aes(x=body_mass_g, fill=species)) + geom_density(alpha=0.8)
#position='identity' makes sure its not stacked
ggplot(penguins, aes(x=body_mass_g, fill=species, color=species)) + geom_histogram(alpha=0.4, position='identity')
aggregate(body_mass_g ~ species, penguins, mean)
aggregate(body_mass_g ~ species, penguins, length)
# Difference between means:
diff(by(penguins$body_mass_g, penguins$species, mean))
#position='identity' makes sure its not stacked
ggplot(penguins, aes(x=body_mass_g, fill=species, color=species)) + geom_histogram(alpha=0.4, position='identity')
# For now let's limit test to difference between body mass of Adelie and Chinstrap
test_df = penguins[penguins$species == c('Adelie','Chinstrap'), c("species","body_mass_g")]
# Removing unused factor level:
test_df$species = factor(test_df$species)
# Difference between means:
diff(by(penguins$body_mass_g, penguins$species, mean))
View(test_df)
# Difference between means:
diff(by(penguins$body_mass_g, penguins$species, mean),na.omit())
test_df_no_na = na.omit(test_df)
# Difference between means:
diff(by(test_df$body_mass_g, test_df$species, mean))
# Look at length and mean
aggregate(body_mass_g ~ species, penguins, mean)
# Difference between means:
diff(by(test_df$body_mass_g, test_df$species, mean))
aggregate(body_mass_g ~ species, penguins, mean)
aggregate(body_mass_g ~ species, penguins, length)
aggregate(body_mass_g ~ species, test_df, mean)
head(penguins,5)
aggregate(body_mass_g ~ species, penguins, length)
penguins_df = penguins
View(penguins_df)
penguins_df = na.omit(penguins)
aggregate(body_mass_g ~ species, penguins, length)
aggregate(body_mass_g ~ species, penguins, length)
aggregate(body_mass_g ~ species, penguins_df, length)
aggregate(body_mass_g ~ species, penguins, length)
# For now let's limit test to difference between body mass of Adelie and Chinstrap
test_df = penguins[penguins$species %in% c('Adelie','Chinstrap'), c("species","body_mass_g")]
aggregate(body_mass_g ~ species, test_df, mean)
aggregate(body_mass_g ~ species, test_df, length)
View(test_df)
t.test(test_df$species ~ test_df$body_mass_g)
# Removing unused factor level:
test_df$species = factor(test_df$species)
t.test(test_df$species ~ test_df$body_mass_g)
t.test(test_df$body_mass_g ~ test_df$species)
plot(x=seq(-3,3,0.1), y= dt(seq(-3,3,0.1),df=152.45),type='l')
abline(v=-0.54309, col = "blue", lwd = 2)
# obtain p-value:
2*pt(0.54309,df=152.45,lower.tail = FALSE)
# obtain p-value:
pt(0.54309,df=152.45,lower.tail = FALSE)
plot(x=seq(-3,3,0.1), y= dt(seq(-3,3,0.1),df=152.45),type='l')
abline(v=-0.54309, col = "blue", lwd = 2)
abline(v=+0.54309, col = "blue", lwd = 2)
# In Welsch t-test, when variances are unequal the df can be non integer
plot(x=seq(-3,3,0.1), y= dt(seq(-3,3,0.1),df=152.45),
type='l',
xlab = 'T-Score',
ylab = 'Probability Density',
main = 't distribution with df=152.45')
abline(v=-0.54309, col = "blue", lwd = 2)
library(coin)
independence_test(test_df$body_mass_g ~ test_df$species)
simple_model = lm(body_mass_g ~ species, data = test_df)
summary(simple_model)
aggregate(body_mass_g ~ species, test_df, mean)
simple_model$coefficients[1]
simple_model$coefficients[2]
simple_model$coefficients[1]
simple_model$coefficients[2]
plot.default(x=test_df$species, y=test_df$body_mass_g)
lines(test_df$species, predict(simple_model),col='blue')
lines(test_df$species, predict(simple_model),col='blue')
simple_model = lm(body_mass_g ~ species, data = test_df)
summary(simple_model)
plot.default(x=test_df$species, y=test_df$body_mass_g)
lines(test_df$species, predict(simple_model),col='blue')
# Remove NAs
penguins_df = na.omit(penguins)
# For now let's limit test to difference between body mass of Adelie and Chinstrap
test_df = penguins_df[penguins_df$species %in% c('Adelie','Chinstrap'), c("species","body_mass_g")]
# Removing unused factor level:
test_df$species = factor(test_df$species)
aggregate(body_mass_g ~ species, test_df, mean)
simple_model = lm(body_mass_g ~ species, data = test_df)
summary(simple_model)
simple_model$coefficients[2]
plot.default(x=test_df$species, y=test_df$body_mass_g)
lines(test_df$species, predict(simple_model),col='blue')
# Difference between means:
diff(by(test_df$body_mass_g, test_df$species, mean))
three_lvl_aov = aov(body_mass_g ~ species, data = penguins_df)
library(palmerpenguins) # Dr. Kristen Gorman
library(ggplot2)
library(coin)
library(scatterplot3d)
# Remove NAs
penguins_df = na.omit(penguins)
three_lvl_model = lm(body_mass_g ~ species, data = penguins_df)
summary(three_lvl_model)
three_lvl_aov = aov(body_mass_g ~ species, data = penguins_df)
anova(three_lvl_aov)
summary(three_lvl_aov)
TukeyHSD(three_lvl_aov)
penguins_df_2 = penguins_df
penguins_df_2$species = factor(penguins_df_2$species, levels = c('Gentoo','Adelie','Chinstrap'))
three_lvl_model = lm(body_mass_g ~ species, data = penguins_df_2)
summary(three_lvl_model)
# Manually create dummy variables:
penguins_df$x1 = ifelse(penguins_df$species == 'Adelie',1,0)
penguins_df$x2 = ifelse(penguins_df$UDF_text_07 == 'Chinstrap',1,0)
# Manually create dummy variables:
penguins_df$x1 = ifelse(penguins_df$species == 'Adelie',1,0)
penguins_df$x2 = ifelse(penguins_df$species == 'Chinstrap',1,0)
# Double check that this is the same as the model we did before with UDF_text_07
model3 = lm(body_mass_g ~ x1 + x2, data = penguins_df)
summary(model3)
# Double check that this is the same as the model we did before with UDF_text_07
model3 = lm(body_mass_g ~ x1 + x2 + x1:x2, data = penguins_df)
summary(model3)
# Double check that this is the same as the model we did before with UDF_text_07
model3 = lm(body_mass_g ~ x1*x2, data = penguins_df)
summary(model3)
# Double check that this is the same as the model we did before with UDF_text_07
model3 = lm(body_mass_g ~ x1+x2, data = penguins_df)
summary(model3)
three_lvl_model = lm(body_mass_g ~ species, data = penguins_df)
summary(three_lvl_model)
# Manually create dummy variables:
penguins_df$x1 = ifelse(penguins_df$species == 'Chinstrap',1,0)
penguins_df$x2 = ifelse(penguins_df$species == 'Gentoo',1,0)
# Double check that this is the same as the model we did before with UDF_text_07
model3 = lm(body_mass_g ~ x1+x2, data = penguins_df)
summary(model3)
s3d = scatterplot3d(z=d$WordCount, x=d$x1, y=d$x2)
s3d = scatterplot3d(z=penguins_df$WordCount, x=penguins_df$x1, y=penguins_df$x2)
s3d$plane3d(model3,draw_polygon = TRUE)
s3d = scatterplot3d(z=penguins_df$body_mass_g, x=penguins_df$x1, y=penguins_df$x2)
s3d$plane3d(model3,draw_polygon = TRUE)
three_lvl_model = lm(body_mass_g ~ species, data = penguins_df)
summary(three_lvl_model)
plot.default(x=penguins_df$species,y=penguins_df$body_mass_g)
lines(penguins_df$species, predict(three_lvl_model),col='blue')
# Look at mean and number of obsvervations for each group
aggregate(body_mass_g ~ species, penguins_df, mean)
aggregate(body_mass_g ~ species, penguins_df, length)
# Here we keep rows that contain Adelie or Chinstrap and only keep species and body_mass_g column
test_df = penguins_df[penguins_df$species %in% c('Adelie','Chinstrap'), c("species","body_mass_g")]
# Removing unused factor level:
test_df$species = factor(test_df$species)
# Look at mean and number of obsvervations for each group
aggregate(body_mass_g ~ species, test_df, mean)
aggregate(body_mass_g ~ species, test_df, length)
# Difference between means:
diff(by(test_df$body_mass_g, test_df$species, mean))
t.test(test_df$body_mass_g ~ test_df$species)
independence_test(test_df$body_mass_g ~ test_df$species)
two_lvl_model = lm(body_mass_g ~ species, data = test_df)
summary(two_cat_model)
two_lvl_model = lm(body_mass_g ~ species, data = test_df)
summary(two_lvl_model)
library(palmerpenguins) # Dr. Kristen Gorman
library(ggplot2)
library(coin)
library(scatterplot3d)
head(penguins,5)
# Remove NAs
penguins_df = na.omit(penguins)
library(palmerpenguins) # Dr. Kristen Gorman
library(ggplot2)
library(coin)
library(scatterplot3d)
head(penguins,10)
penguins
# Look at mean and number of obsvervations for each group
aggregate(body_mass_g ~ species, penguins_df, mean)
aggregate(body_mass_g ~ species, penguins_df, length)
# Here we keep rows that contain Adelie or Chinstrap and only keep species and body_mass_g column
test_df = penguins_df[penguins_df$species %in% c('Adelie','Chinstrap'), c("species","body_mass_g")]
# Removing unused factor level:
test_df$species = factor(test_df$species)
# Look at mean and number of obsvervations for each group
aggregate(body_mass_g ~ species, test_df, mean)
aggregate(body_mass_g ~ species, test_df, length)
# Difference between means:
diff(by(test_df$body_mass_g, test_df$species, mean))
two_lvl_model = lm(body_mass_g ~ species, data = test_df)
summary(two_lvl_model)
t.test(test_df$body_mass_g ~ test_df$species)
independence_test(test_df$body_mass_g ~ test_df$species)
t.test(test_df$body_mass_g ~ test_df$species,var.equal='T')
t.test(test_df$body_mass_g ~ test_df$species, var.equal=T)
# If you set var.equal = T it will give the same t-value & p-value as the regression
t.test(test_df$body_mass_g ~ test_df$species)
# If you set var.equal = T it will give the same t-value & p-value as the regression
t.test(test_df$body_mass_g ~ test_df$species, var.equal = T)
sd(test_df$body_mass_g)
var(test_df$body_mass_g[test_df$species == "Chinstrap"])
two_lvl_model = lm(body_mass_g ~ species, data = test_df)
summary(two_lvl_model)
var(test_df$body_mass_g[test_df$species == "Chinstrap"])
var(test_df$body_mass_g[test_df$species == "Adelie"])
length(test_df$body_mass_g[test_df$species == "Adelie"])
length(test_df$body_mass_g[test_df$species == "Chinstrap"])
var(test_df$body_mass_g[test_df$species == "Chinstrap"])
var(test_df$body_mass_g[test_df$species == "Adelie"])
length(test_df$body_mass_g[test_df$species == "Adelie"])
length(test_df$body_mass_g[test_df$species == "Chinstrap"])
var(test_df$body_mass_g[test_df$species == "Chinstrap"])
var(test_df$body_mass_g[test_df$species == "Adelie"])
length(test_df$body_mass_g[test_df$species == "Chinstrap"])
length(test_df$body_mass_g[test_df$species == "Adelie"])
(147713.5 * 67 + 145 * 210332.4) / 212
(147713.5 * 67 + 145 * 210332.4) / 212
sqrt((147713.5 * 67 + 145 * 210332.4) / 212)
# Variacne estimator of coefficients from linear model that meets assumptions:
# In this case Xs are just 0 or 1, Y is the body mass for respective species
var(test_df$body_mass_g[test_df$species == "Chinstrap"])
var(test_df$body_mass_g[test_df$species == "Adelie"])
length(test_df$body_mass_g[test_df$species == "Chinstrap"])
length(test_df$body_mass_g[test_df$species == "Adelie"])
sqrt( ((147713.5 * 67 + 145 * 210332.4) / 212) * (1/68 + 1/146) )
library(palmerpenguins) # Dr. Kristen Gorman
library(ggplot2)
library(coin)
library(scatterplot3d)
penguins
# Remove NAs
penguins_df = na.omit(penguins)
# Look at mean and number of obsvervations for each group
aggregate(body_mass_g ~ species, penguins_df, mean)
aggregate(body_mass_g ~ species, penguins_df, length)
# Here we keep rows that contain Adelie or Chinstrap and only keep species and body_mass_g column
test_df = penguins_df[penguins_df$species %in% c('Adelie','Chinstrap'), c("species","body_mass_g")]
# Removing unused factor level:
test_df$species = factor(test_df$species)
# Look at mean and number of obsvervations for each group
aggregate(body_mass_g ~ species, test_df, mean)
aggregate(body_mass_g ~ species, test_df, length)
# Difference between means:
diff(by(test_df$body_mass_g, test_df$species, mean))
two_lvl_model = lm(body_mass_g ~ species, data = test_df)
summary(two_lvl_model)
var(two_lvl_model$resid)
sum( (test_df$body_mass_g - mean(test_df$body_mass_g) )^2 )
sum( (test_df$body_mass_g - mean(test_df$body_mass_g) )^2 ) / var(two_lvl_model$resid)
var(two_lvl_model$resid) / sum( (test_df$body_mass_g - mean(test_df$body_mass_g) )^2 )
# Pooled variance:
(147713.5 * 67 + 145 * 210332.4) / 212
two_lvl_model$residuals
var(two_lvl_model$residuals) / sum( (test_df$body_mass_g - mean(test_df$body_mass_g) )^2 )
var(two_lvl_model$residuals) / sqrt(sum( (test_df$body_mass_g - mean(test_df$body_mass_g) )^2 ))
sqrt(var(two_lvl_model$residuals)/ (length(two_lvl_model$residuals) - 2) ) / sqrt(sum( (test_df$body_mass_g - mean(test_df$body_mass_g) )^2 ))
sqrt(var(two_lvl_model$residuals)/ (length(two_lvl_model$residuals) - 2) )
sqrt(sum( (test_df$body_mass_g - mean(test_df$body_mass_g) )^2 ))
var(two_lvl_model$residuals)/ (length(two_lvl_model$residuals) - 2)
# Pooled variance:
(147713.5 * 67 + 145 * 210332.4) / 212
var(two_lvl_model$residuals)
var(two_lvl_model$residuals) / 212
var(two_lvl_model$residuals)
var(two_lvl_model$residuals) / sqrt(sum( (test_df$body_mass_g - mean(test_df$body_mass_g) )^2 ))
sum( (two_lvl_model$residuals - mean(two_lvl_model$residuals) )^2
sum( (two_lvl_model$residuals - mean(two_lvl_model$residuals) )^2)
sum((two_lvl_model$residuals - mean(two_lvl_model$residuals))^2)
var(two_lvl_model$residuals) / sqrt(sum( (test_df$body_mass_g - mean(test_df$body_mass_g) )^2 ))
sum((two_lvl_model$residuals - mean(two_lvl_model$residuals))^2) / (length( two_lvl_model$residuals) - 2)
sum((two_lvl_model$residuals - mean(two_lvl_model$residuals))^2) / (length( two_lvl_model$residuals) - 2) / sqrt(sum( (test_df$body_mass_g - mean(test_df$body_mass_g) )^2 ))
sum((two_lvl_model$residuals - mean(two_lvl_model$residuals))^2) / (length( two_lvl_model$residuals) - 3) / sqrt(sum( (test_df$body_mass_g - mean(test_df$body_mass_g) )^2 ))
sum((two_lvl_model$residuals - mean(two_lvl_model$residuals))^2) / (length( two_lvl_model$residuals) - 1) / sqrt(sum( (test_df$body_mass_g - mean(test_df$body_mass_g) )^2 ))
sum((two_lvl_model$residuals - mean(two_lvl_model$residuals))^2) / (length( two_lvl_model$residuals) - 2) / sqrt(sum( (test_df$body_mass_g - mean(test_df$body_mass_g) )^2 ))
sqrt(sum((two_lvl_model$residuals - mean(two_lvl_model$residuals))^2) / (length( two_lvl_model$residuals) - 2)) / sqrt(sum( (test_df$body_mass_g - mean(test_df$body_mass_g) )^2 ))
# Pooled standard error:
sqrt( ((147713.5 * 67 + 145 * 210332.4) / 212) * (1/68 + 1/146) )
# Pooled variance:
(147713.5 * 67 + 145 * 210332.4) / 212
var(two_lvl_model$residuals)
sqrt(sum((two_lvl_model$residuals - mean(two_lvl_model$residuals))^2))
sum((two_lvl_model$residuals - mean(two_lvl_model$residuals))^2)
sum((two_lvl_model$residuals - mean(two_lvl_model$residuals))^2) / length(two_lvl_model$residuals)
sum((two_lvl_model$residuals - mean(two_lvl_model$residuals))^2) / (length(two_lvl_model$residuals) - 2)
var(two_lvl_model$residuals)
sum((two_lvl_model$residuals - mean(two_lvl_model$residuals))^2) / (length(two_lvl_model$residuals) - 2)
sum( (test_df$body_mass_g - mean(test_df$body_mass_g) )^2)
sqrt(sum( (test_df$body_mass_g - mean(test_df$body_mass_g) )^2))
sqrt(sum((two_lvl_model$residuals - mean(two_lvl_model$residuals))^2) / (length(two_lvl_model$residuals) - 2))
sqrt(sum((two_lvl_model$residuals - mean(two_lvl_model$residuals))^2) / (length( two_lvl_model$residuals) - 2)) / sqrt(sum( (test_df$body_mass_g - mean(test_df$body_mass_g) )^2 ))
sqrt(sum((two_lvl_model$residuals - mean(two_lvl_model$residuals))^2) / (length(two_lvl_model$residuals) - 2))
sqrt(sum( (test_df$body_mass_g - mean(test_df$body_mass_g) )^2))
(sum((two_lvl_model$residuals - mean(two_lvl_model$residuals))^2) / (length(two_lvl_model$residuals) - 2) ) / sum( (test_df$body_mass_g - mean(test_df$body_mass_g) )^2)
sqrt((sum((two_lvl_model$residuals - mean(two_lvl_model$residuals))^2) / (length(two_lvl_model$residuals) - 2) ) / sum( (test_df$body_mass_g - mean(test_df$body_mass_g) )^2))
sum( (test_df$species - mean(test_df$species) )^2)
(sum((two_lvl_model$residuals - mean(two_lvl_model$residuals))^2) / (length(two_lvl_model$residuals) - 2) )
(sum((two_lvl_model$residuals - mean(two_lvl_model$residuals))^2) / (length(two_lvl_model$residuals) - 2) ) / 0.5
sqrt((sum((two_lvl_model$residuals - mean(two_lvl_model$residuals))^2) / (length(two_lvl_model$residuals) - 2) ) / 0.5)
sqrt((sum((two_lvl_model$residuals - mean(two_lvl_model$residuals))^2) / (length(two_lvl_model$residuals) - 2) )) / sqrt(0.5)
sqrt((sum((two_lvl_model$residuals - mean(two_lvl_model$residuals))^2) / (length(two_lvl_model$residuals) - 2) )) / sqrt(0.25)
sqrt((sum((two_lvl_model$residuals - mean(two_lvl_model$residuals))^2) / (length(two_lvl_model$residuals) - 2) )) / sqrt(0.75)
sqrt((sum((two_lvl_model$residuals - mean(two_lvl_model$residuals))^2) / (length(two_lvl_model$residuals) - 2) )) / 1
sqrt((sum((two_lvl_model$residuals - mean(two_lvl_model$residuals))^2) / (length(two_lvl_model$residuals) - 2) )) / 1.5
(1/68 + 1/146)
sqrt((sum((two_lvl_model$residuals - mean(two_lvl_model$residuals))^2) / (length(two_lvl_model$residuals) - 2) )) /
0.5 *2
sqrt((sum((two_lvl_model$residuals - mean(two_lvl_model$residuals))^2) / (length(two_lvl_model$residuals) - 2) )) /
0.5 *2
0.5 *2
0.5 *3
0.5 * (len(test_df$body_mass_g))
0.5 * (length(test_df$body_mass_g))
sqrt((sum((two_lvl_model$residuals - mean(two_lvl_model$residuals))^2) / (length(two_lvl_model$residuals) - 2) )) / 107
sqrt((sum((two_lvl_model$residuals - mean(two_lvl_model$residuals))^2) / (length(two_lvl_model$residuals) - 2) )) / sqrt(107)
0.25 * (length(test_df$body_mass_g))
sqrt((sum((two_lvl_model$residuals - mean(two_lvl_model$residuals))^2) / (length(two_lvl_model$residuals) - 2) )) / sqrt(53.5)
n1 = length(test_df$body_mass_g[test_df$species == "Chinstrap"])
n2 = length(test_df$body_mass_g[test_df$species == "Adelie"])
(146/214) * (length(test_df$body_mass_g))
sqrt((sum((two_lvl_model$residuals - mean(two_lvl_model$residuals))^2) / (length(two_lvl_model$residuals) - 2) )) / sqrt(146)
1 - (146/214)
0 - (146/214)
1 - (146/214)
1 - (146/214) * 146
(0 - (146/214)) * 68
(0 - (146/214))^2 * 68
(1 - (146/214))^2 * 146
sqrt((sum((two_lvl_model$residuals - mean(two_lvl_model$residuals))^2) / (length(two_lvl_model$residuals) - 2) )) / sqrt(31+14)
(1 - (146/214))^2 * 146
(0 - (146/214))^2 * 68
sqrt((sum((two_lvl_model$residuals - mean(two_lvl_model$residuals))^2) / (length(two_lvl_model$residuals) - 2) )) / sqrt(31.65097+14.74155)
library(palmerpenguins)
library(ggplot2)
library(scatterplot3d)
penguins
# Here we keep rows that contain Adelie or Chinstrap and only keep species and body_mass_g column
test_df = penguins_df[penguins_df$species %in% c('Adelie','Chinstrap'), c("species","body_mass_g")]
# Remove NAs
penguins_df = na.omit(penguins)
#position='identity' makes sure its not stacked
#ggplot(penguins_df, aes(x=body_mass_g, fill=species, color=species)) + geom_histogram(alpha=0.4, position='identity')
ggplot(penguins_df, aes(x=body_mass_g, fill=species)) + geom_density(alpha=0.8)
# Look at mean and number of obsvervations for each group
aggregate(body_mass_g ~ species, penguins_df, mean)
aggregate(body_mass_g ~ species, penguins_df, length)
# Here we keep rows that contain Adelie or Chinstrap and only keep species and body_mass_g column
test_df = penguins_df[penguins_df$species %in% c('Adelie','Chinstrap'), c("species","body_mass_g")]
# Create factors again to remove unused factor level:
test_df$species = factor(test_df$species)
# Look at mean and number of obsvervations for each group
aggregate(body_mass_g ~ species, test_df, mean)
aggregate(body_mass_g ~ species, test_df, length)
# Difference between means:
diff(by(test_df$body_mass_g, test_df$species, mean))
two_lvl_model = lm(body_mass_g ~ species, data = test_df)
summary(two_lvl_model)
# Intercept:
two_lvl_model$coefficients[1]
# Slope
two_lvl_model$coefficients[2]
# Intercept:
two_lvl_model$coefficients[1]
# Slope
two_lvl_model$coefficients[2]
# Here we keep rows that contain Adelie or Chinstrap and only keep species and body_mass_g column
test_df = penguins_df[penguins_df$species %in% c('Adelie','Chinstrap'), c("species","body_mass_g")]
# Create factors again to remove unused factor level:
test_df$species = factor(test_df$species)
# Difference between means:
diff(by(test_df$body_mass_g, test_df$species, mean))
# Manually create dummy variables:
penguins_df$x1 = ifelse(penguins_df$species == 'Chinstrap',1,0)
penguins_df$x2 = ifelse(penguins_df$species == 'Gentoo',1,0)
penguins_df
# Double check that this is the same as the model we did before with UDF_text_07
model3 = lm(body_mass_g ~ x1+x2, data = penguins_df)
summary(model3)
sqrt(sum((two_lvl_model$residuals - mean(two_lvl_model$residuals))^2) / (length( two_lvl_model$residuals) - 2)) / sqrt(sum( (test_df$x - mean(test_df$x) )^2 ))
# Manually create dummy variables:
test_df$x = ifelse(test_df$species == 'Chinstrap',1,0)
# Variacne estimator of coefficients from linear model that meets assumptions:
# In this case Xs are just 0 or 1, Y is the body mass for respective species
var1 = var(test_df$body_mass_g[test_df$species == "Chinstrap"])
var2 = var(test_df$body_mass_g[test_df$species == "Adelie"])
n1 = length(test_df$body_mass_g[test_df$species == "Chinstrap"])
n2 = length(test_df$body_mass_g[test_df$species == "Adelie"])
# Pooled variance:
var_pool = ( (n1-1)*var1 + (n2-1) * var2) / (n1+n2-2)
# Pooled standard error:
se_pool = sqrt( var_pool * (1/n1 + 1/n2) )
sqrt(sum((two_lvl_model$residuals - mean(two_lvl_model$residuals))^2) / (length( two_lvl_model$residuals) - 2)) / sqrt(sum( (test_df$x - mean(test_df$x) )^2 ))
sqrt((sum((two_lvl_model$residuals - mean(two_lvl_model$residuals))^2) / (length(two_lvl_model$residuals) - 2) ))
sum( (test_df$x - mean(test_df$x) )^2 )
sum((two_lvl_model$residuals - mean(two_lvl_model$residuals))^2
sum((two_lvl_model$residuals - mean(two_lvl_model$residuals))^2)
sum((two_lvl_model$residuals - mean(two_lvl_model$residuals))
sum((two_lvl_model$residuals - mean(two_lvl_model$residuals)))
sum(two_lvl_model$residuals - mean(two_lvl_model$residuals))
var(two_lvl_model$residuals)
var(two_lvl_model$residuals) / sum( (test_df$x - mean(test_df$x) )^2 )
sum(two_lvl_model$residuals - mean(two_lvl_model$residuals))
sum( (two_lvl_model$residuals - mean(two_lvl_model$residuals))^2 )
sum( (two_lvl_model$residuals - mean(two_lvl_model$residuals))^2 ) / sum( (test_df$x - mean(test_df$x) )^2 )
sum( (two_lvl_model$residuals - mean(two_lvl_model$residuals))^2 ) / (length( two_lvl_model$residuals) - 2)) / sum( (test_df$x - mean(test_df$x) )^2 )
sum( (two_lvl_model$residuals - mean(two_lvl_model$residuals))^2 ) / (length( two_lvl_model$residuals) - 2) / sum( (test_df$x - mean(test_df$x) )^2 )
(sum( (two_lvl_model$residuals - mean(two_lvl_model$residuals))^2 ) / (length( two_lvl_model$residuals) - 2)) / sum( (test_df$x - mean(test_df$x) )^2 )
var(two_lvl_model$residuals)
sqrt(var(two_lvl_model$residuals))
var(two_lvl_model$residuals)
# SE of the slope is the same as SE pooled
sqrt(sum((two_lvl_model$residuals - mean(two_lvl_model$residuals))^2) / (length( two_lvl_model$residuals) - 2)) / sqrt(sum( (test_df$x - mean(test_df$x) )^2 ))
library(htmltools)
install.packages("htmltools")
install.packages("blogdown")
install.packages("blogdown")
install.packages("blogdown")
devtools::install_github("rstudio/blogdown")
install.packages("devtools")
devtools::install_github("rstudio/blogdown")
blogdown::serve_site()
getcwd()
getwd()
?chdir
setwd('C:/Users/Laagi.yoganathan/Documents/GitLab/lyoganathan.github.io')
blogdown::serve_site()
blogdown::config_Rprofile()
blogdown::serve_site()
knitr::knit()
